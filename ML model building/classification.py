# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1P7vSC_K7BIBkMNpMZvOESpAOJ5yk_WEL
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

dataset = pd.read_csv('Activity_sheet_final_God_100nM.csv')
dataset.head()

x = dataset.drop(['Response'], axis = 1)
y = dataset['Response']

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)

# Commented out IPython magic to ensure Python compatibility.
# %pip install mlxtend --upgrade

from mlxtend.feature_selection import SequentialFeatureSelector as sfs
from sklearn.linear_model import LinearRegression
lreg = LinearRegression()
sfs1 = sfs(lreg, k_features = 5, forward = True, verbose = 2, scoring ='roc_auc')
sfs1 = sfs1.fit(x_train, y_train)

feat_names = list(sfs1.k_feature_names_)
print(feat_names)

new_train_data = x_train[feat_names]
print(new_train_data)

from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier()
classifier.fit(new_train_data, y_train)

from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression(random_state = 42)
classifier.fit(new_train_data, y_train)

from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(random_state = 42, n_estimators=1000)
classifier.fit(new_train_data, y_train)

from sklearn.svm import SVC
classifier = SVC(random_state = 42)
classifier.fit(new_train_data, y_train)

from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB()
classifier.fit(new_train_data, y_train)

parameters = [{'C': [0.25, 0.5, 0.75, 1, 10, 20, 50, 100],
               'kernel': ['rbf'],
               'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]

classifier = SVC(random_state = 42)
classifier.fit(new_train_data, y_train)

from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV

#grid search
cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state=42)
grid_search = GridSearchCV(estimator = classifier, param_grid=parameters, n_jobs = 1, cv=cv, scoring = 'balanced_accuracy')

grid_search.fit(new_train_data, y_train)
best_parameters = grid_search.best_params_
print("Best Parameters:", best_parameters)
print(classifier)

from sklearn.svm import SVC
classifier = SVC(C = 0.25, gamma = 0.1, kernel = 'rbf', random_state = 42)
classifier.fit(new_train_data, y_train)

y_pred_train = classifier.predict(new_train_data)
from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, balanced_accuracy_score
cm = confusion_matrix(y_train, y_pred_train)
print(cm)
accuracy = accuracy_score(y_train, y_pred_train)
f1_score = f1_score(y_train, y_pred_train)
precision = precision_score(y_train, y_pred_train)
recall = recall_score(y_train, y_pred_train)
roc_auc = roc_auc_score(y_train, y_pred_train)
balanced_accuracy = balanced_accuracy_score(y_train, y_pred_train)
print(accuracy)
print(f1_score)
print(precision)
print(recall)
print(roc_auc)
print(balanced_accuracy)

new_test_data = x_test[feat_names]
#print(new_test_data)
y_pred = classifier.predict(new_test_data)

from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score,balanced_accuracy_score
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy = accuracy_score(y_test, y_pred)
f1_score = f1_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_pred)
balanced_accuracy = balanced_accuracy_score(y_test, y_pred)
print(accuracy)
print(f1_score)
print(precision)
print(recall)
print(roc_auc)
print(balanced_accuracy)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, y_pred, labels=classifier.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=classifier.classes_)
disp.plot()

from sklearn.model_selection import cross_val_score, StratifiedKFold

# Define your classifier (SVC in this case)
classifier = SVC(random_state=42)

# Define the cross-validation method (StratifiedKFold with 5 folds)
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Perform cross-validation and get accuracy scores
cv_scores = cross_val_score(classifier, new_train_data, y_train, cv=cv, scoring='recall')

# Print the cross-validation scores
print("Cross-Validation Scores:", cv_scores)

# Calculate and print the mean and standard deviation of the scores
mean_recall = cv_scores.mean()
print("Mean recall:", mean_recall)

#y-randomization

num_permutations = 200

for _ in range(num_permutations):
        # Shuffle the target variable 'y'
        y_shuffled = np.random.permutation(y_train)

# Fit the model with the shuffled 'y'
print(y_shuffled)
classifier.fit(new_train_data, y_shuffled)

y_pred_shuffled = classifier.predict(new_test_data)

from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score,balanced_accuracy_score
cm = confusion_matrix(y_test, y_pred_shuffled)
print(cm)
accuracy = accuracy_score(y_test, y_pred_shuffled)
f1_score = f1_score(y_test, y_pred_shuffled)
precision = precision_score(y_test, y_pred_shuffled)
recall = recall_score(y_test, y_pred_shuffled)
roc_auc = roc_auc_score(y_test, y_pred_shuffled)
balanced_accuracy = balanced_accuracy_score(y_test, y_pred_shuffled)
print(accuracy)
print(f1_score)
print(precision)
print(recall)
print(roc_auc)
print(balanced_accuracy)
